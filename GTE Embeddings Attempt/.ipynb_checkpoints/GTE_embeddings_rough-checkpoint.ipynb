{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1681581a-ed0b-4a4d-9b16-c68d912bf9a5",
   "metadata": {},
   "source": [
    "# GTE Embeddings Project\n",
    "\n",
    "## Charlie Perez for the Julian Bond Papers Project\n",
    "\n",
    "This project is extremely vague but I think we can apply Lucian's framework discussed in \"Tracing the Genealogies of Ideas\" (https://arxiv.org/pdf/2402.01661v1) to the corpus of Bond's speeches. Lucian's framework took a long time to implement, though, and I can't find an open source repo on the internet, yet. I'm thinking I may need to email him. But in the meantime, I want to try and replicate the process. This work is conducted with Lucian's text as a reference.\n",
    "\n",
    "Also, credit to the developers of SentenceTransformers package which I have used to create and analyze these embeddings:\n",
    "\n",
    "- https://www.sbert.net/\n",
    "- https://arxiv.org/abs/1908.10084\n",
    "\n",
    "and to the GTE-small model that I am using to create these embeddings with SentenceTransformers:\n",
    "\n",
    "- https://huggingface.co/thenlper/gte-small\n",
    "- https://arxiv.org/abs/2308.03281\n",
    "\n",
    "(Yeah, I need to cite these more thoroughly. I'll get around to it.)\n",
    "\n",
    "I am also taking a class that will cover NLP and unsupervised learning methods on large corpus text data this semester, so I am guessing I will learn how to do many steps along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5a08d-65ef-472f-87a9-fa7ffce30b03",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "\n",
    "Required packages include NLTK, sentence-transformers, FAISS\n",
    "\n",
    "1. Scrape the Bond speeches that are available from Drupal to give us a corpus to work with.\n",
    "\n",
    "2. Organize all of these speeches into a suitable data structure (separate into sentences, provdie sufficient metadata to link them). Lucian said he eliminated items from the corpus that were works < 1000 characters and sentences < 45 words. I think that in this case, the former restriction makes sense but the latter does not and we will need to include shorter sentences.\n",
    "\n",
    "3. Preprocessing, including tokenization with NLTK.\n",
    "\n",
    "4. Use GTE-small to create sentence-level embeddings, then search for similarities using FAISS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73caae-7fd2-4f59-b9f1-f7074c91d3f1",
   "metadata": {},
   "source": [
    "## Test: \n",
    "\n",
    "let's see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f75fb58b-dce1-4723-a759-68f710947627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# this is just to get rid of an error message - something about how Windows caches the model I'm downloading from the internet\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9be0494a-f893-417c-98b7-cb91647a6d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Box</th>\n",
       "      <th>Document Length</th>\n",
       "      <th>Workflow Stage</th>\n",
       "      <th>Image Filename</th>\n",
       "      <th>Image Identifier</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Document Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>667</td>\n",
       "      <td>Speeches making observations about the recent ...</td>\n",
       "      <td>Box 3 Folder 31</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Early Access</td>\n",
       "      <td>PJB667_mss13347-b3-f31_0049.tif\\n, PJB667_mss1...</td>\n",
       "      <td>3191384, 3191385, 3191386, 3191387, 3191388, 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now that the nation's voters — at least, 54% o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>666</td>\n",
       "      <td>Speeches making observations about the recent ...</td>\n",
       "      <td>Box 3 Folder 31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Early Access</td>\n",
       "      <td>PJB666_mss13347-b3-f31_0025.tif\\n, PJB666_mss1...</td>\n",
       "      <td>3191361, 3191362, 3191363, 3191364, 3191365, 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now that the nation's voters — at least, 54% o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   ID                                              Title  \\\n",
       "0      5  667  Speeches making observations about the recent ...   \n",
       "1      6  666  Speeches making observations about the recent ...   \n",
       "\n",
       "               Box  Document Length Workflow Stage  \\\n",
       "0  Box 3 Folder 31             32.0   Early Access   \n",
       "1  Box 3 Folder 31             24.0   Early Access   \n",
       "\n",
       "                                      Image Filename  \\\n",
       "0  PJB667_mss13347-b3-f31_0049.tif\\n, PJB667_mss1...   \n",
       "1  PJB666_mss13347-b3-f31_0025.tif\\n, PJB666_mss1...   \n",
       "\n",
       "                                    Image Identifier Image URL  \\\n",
       "0  3191384, 3191385, 3191386, 3191387, 3191388, 3...       NaN   \n",
       "1  3191361, 3191362, 3191363, 3191364, 3191365, 3...       NaN   \n",
       "\n",
       "                                       Document Body  \n",
       "0  Now that the nation's voters — at least, 54% o...  \n",
       "1  Now that the nation's voters — at least, 54% o...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.read_csv('../document-catalog_extended.csv') # I have this from earlier - it's a CSV export of a bunch of speeches from my location project\n",
    "documents = documents[documents['Workflow Stage'] == 'Early Access']\n",
    "documents_test = documents.iloc[1:3].reset_index()\n",
    "documents_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b0f3eabf-3979-49b9-91d7-ae1cf496b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Now that the nation's voters — at least, 54% of those eligible — have gone to the polls and expressed their choice, we have an opportunity to reflect on why that choice was made, what it meant, and what it will mean in the years ahead\",\n",
       " '\\nThe choice, simply put, was between the past performance of one fallible man and the unproved promises of another',\n",
       " '\\nThose who believed Gallup and Harris knew that the outcome was never in doubt']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_667 = documents_test['Document Body'][0].split('.')\n",
    "\n",
    "# temporary solution to getting rid of short sentences\n",
    "\n",
    "doc_667 = [x for x in doc_667 if len(x) > 50]\n",
    "doc_667[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81a2f6-2cb0-49a1-867b-fee981d46224",
   "metadata": {},
   "source": [
    "I think I will need to start looking into using regex to do lookbehinds and not split on, say, \"Dr.\" or \"W.E.B.\" but fo rnow this will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398a2ea-ba1e-42ca-870c-4b976e7ea66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gonna leave this function here for the future when I can get good at sentence slicing\n",
    "\n",
    "# def sentence_slicing(str):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6778b343-4fb6-4b7d-ab5d-d9715576f208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Now that the nation's voters — at least, 54% of those eligible — have gone to the polls and expressed their choice, we have an opportunity to reflect on why that choice was made, what it meant, and what it will mean in the years ahead\",\n",
       " '\\xa0\\nThe choice, simply put, was between the past performance of one fallible man and the unproved promises of another',\n",
       " '\\nThose who believed Gallup and Harris knew that the outcome was never in doubt']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_666 = documents_test['Document Body'][1].split('.')\n",
    "\n",
    "# temporary solution to getting rid of short sentences\n",
    "\n",
    "doc_666 = [x for x in doc_666 if len(x) > 50]\n",
    "doc_666[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abbb3d9a-1570-4693-817a-07a9d433cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 384)\n",
      "(107, 384)\n",
      "tensor([[1.0000, 0.7993, 0.7778,  ..., 0.7457, 0.7735, 0.8218],\n",
      "        [0.7993, 1.0000, 0.8007,  ..., 0.7503, 0.7861, 0.7680],\n",
      "        [0.7778, 0.8007, 1.0000,  ..., 0.7791, 0.7602, 0.7792],\n",
      "        ...,\n",
      "        [0.8169, 0.7643, 0.7733,  ..., 0.7581, 0.7800, 0.8178],\n",
      "        [0.7489, 0.7607, 0.7258,  ..., 0.7496, 0.7716, 0.7609],\n",
      "        [0.8029, 0.7716, 0.7661,  ..., 0.7850, 0.7978, 0.8117]])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"thenlper/gte-small\")\n",
    "\n",
    "embeddings667 = model.encode(doc_667)\n",
    "print(embeddings667.shape)\n",
    "\n",
    "embeddings666 = model.encode(doc_666)\n",
    "print(embeddings666.shape)\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings667, embeddings666)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c1cd9f5e-4cd2-46b5-b9cc-ac76c6e25c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3],\n",
       "        [4, 4]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "# Find indices where scores >= threshold\n",
    "indices = torch.nonzero(similarities >= threshold)\n",
    "\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f8ddaa93-96a5-424a-b899-07938cf1bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [x.tolist() for x in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e2ed58a4-39aa-4aa8-9fd5-bc799b34fb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_1</th>\n",
       "      <th>Index_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index_1  Index_2\n",
       "0        0        0\n",
       "1        1        1\n",
       "2        2        2\n",
       "3        3        3\n",
       "4        4        4"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sentences = pd.DataFrame(indices)\n",
    "common_sentences.rename(columns={0: 'Index_1', 1: 'Index_2'}, inplace=True)\n",
    "common_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c0a7b5ea-0820-445e-8f7d-d87b7a7d4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for index, row in common_sentences.iterrows():\n",
    "    first = row['Index_1']\n",
    "    second = row['Index_2']\n",
    "    scores.append(round(float(similarities[first][second]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "01842337-6271-428a-81a6-b18b65624c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.992, 0.994]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a0009cc3-5833-4b4b-8599-5790cbe6d43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_1</th>\n",
       "      <th>Index_2</th>\n",
       "      <th>Speech_1</th>\n",
       "      <th>Speech_2</th>\n",
       "      <th>Similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Now that the nation's voters — at least, 54% o...</td>\n",
       "      <td>Now that the nation's voters — at least, 54% o...</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nThe choice, simply put, was between the past...</td>\n",
       "      <td>\\nThe choice, simply put, was between the pas...</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\\nThose who believed Gallup and Harris knew th...</td>\n",
       "      <td>\\nThose who believed Gallup and Harris knew th...</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>We learned that Jews, worried about quotas an...</td>\n",
       "      <td>We learned that Jews, worried about quotas an...</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>] - ---- -- --- -\\nIf the election on November...</td>\n",
       "      <td>\\nIf the election on November 7th illuminated ...</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index_1  Index_2                                           Speech_1  \\\n",
       "0        0        0  Now that the nation's voters — at least, 54% o...   \n",
       "1        1        1  \\nThe choice, simply put, was between the past...   \n",
       "2        2        2  \\nThose who believed Gallup and Harris knew th...   \n",
       "3        3        3   We learned that Jews, worried about quotas an...   \n",
       "4        4        4  ] - ---- -- --- -\\nIf the election on November...   \n",
       "\n",
       "                                            Speech_2  Similarity_score  \n",
       "0  Now that the nation's voters — at least, 54% o...             1.000  \n",
       "1   \\nThe choice, simply put, was between the pas...             1.000  \n",
       "2  \\nThose who believed Gallup and Harris knew th...             1.000  \n",
       "3   We learned that Jews, worried about quotas an...             0.992  \n",
       "4  \\nIf the election on November 7th illuminated ...             0.994  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sentences['Speech_1'] = common_sentences['Index_1'].map(lambda x: doc_667[x])\n",
    "common_sentences['Speech_2'] = common_sentences['Index_2'].map(lambda x: doc_666[x])\n",
    "common_sentences['Similarity_score'] = scores\n",
    "common_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b344cceb-4e94-4fa9-98fc-4368345db99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We learned that Jews, worried about quotas and Israel, would abandon regular Democrats would split over McGovern; that organized labor didn't like him; that factory workers white Southern voters, with George Wallace gone, would go to Nixon; that the wealthy, worried about taxes, would do the same; that the middle class saw safer streets under Nixon; that the \"ethnics\" wanted to crack down on dissenters and deserters and that college students could not stick to anything over a prolonged period of time and that almost no single identifiable group could be found — except for Black people — to cast votes as a bloc for\n",
      "2\n",
      "George McGovern\n",
      "\n",
      " We learned that Jews, worried about quotas and Israel, would abandon McGovern; that organized labor didn't like him; that factory workers, with George Wallace gone, would go to Nixon; that the waethly wealthy, worried about taxes, would do the same; that the middle class saw safer streets under Nixon; that the \"ethnics\" wanted to crack down on dissenters and deserters and that students could not stick to anything over a prolonged period of time and that almost no single identifiable group could be found — except for Black people — to cast votes as a bloc for\n",
      "2\n",
      "George McGovern\n"
     ]
    }
   ],
   "source": [
    "print(common_sentences['Speech_1'][3])\n",
    "print()\n",
    "print(common_sentences['Speech_2'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815a63c-e941-4417-a307-ce2a516f2dda",
   "metadata": {},
   "source": [
    "### In action\n",
    "\n",
    "So we can see that this classifier works pretty well!\n",
    "\n",
    "It's kind of cool, we can see that the only differences are wording changes that were corrected on the page, such as the misspelling of wealthy, or the changing of his wording on the Jewish \"abandonment\" of McGovern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "17fff81f-6170-4cb1-aa4e-6c1c74defdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_1</th>\n",
       "      <th>Index_2</th>\n",
       "      <th>Speech_1</th>\n",
       "      <th>Speech_2</th>\n",
       "      <th>Similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>\"\\n\"But if we solve the greatest of our ills,\"...</td>\n",
       "      <td>\"1\\nBut in addition to the Coalition's major g...</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index_1  Index_2                                           Speech_1  \\\n",
       "22       21       27  \"\\n\"But if we solve the greatest of our ills,\"...   \n",
       "\n",
       "                                             Speech_2  Similarity_score  \n",
       "22  \"1\\nBut in addition to the Coalition's major g...             0.904  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_similar = common_sentences[common_sentences['Similarity_score'] == min(common_sentences['Similarity_score'])]\n",
    "least_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f10e8a4c-7114-4212-81ba-ffea7f2cd413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\"But if we solve the greatest of our ills,\" the Coalition said, \"our paralysis of spirit and will, we can narrow the distance between what we have and what we want\n",
      "\n",
      "\"1\n",
      "But in addition to the Coalition's major goals, and their definition of \"paralysis of will\" as the greatest of our ills, there is another goal much more desirable\n"
     ]
    }
   ],
   "source": [
    "print(common_sentences['Speech_1'][22])\n",
    "print()\n",
    "print(common_sentences['Speech_2'][22])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d317eb78-8592-4b5b-aa98-9620a134cbca",
   "metadata": {},
   "source": [
    "And here, we can see that this has been much more significantly altered between the two drafts, but carries a similar message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c045c-de6e-44b2-9572-fd3f9a21ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create a method to build these dataframes\n",
    "\n",
    "# def organize_dataframe(speech1, speech2, indices):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f5d56-aca1-4c4b-815d-83c745a756cb",
   "metadata": {},
   "source": [
    "I'm starting to see how this might be simpler with a bit of a more expansive design here. I think the end goal looks something like this:\n",
    "\n",
    "1. Create and save an embedding object for each Bond speech. This already contains the relative \"size\" of the speech (it is the number of rows in the embedding object) so we can also note how many of the lines share in similarity.\n",
    "2. From the embedding object, we can create a comparison object between two embedding objects.\n",
    "3. The comparison object will consist of a list object with all its similarity stats and a dataframe that does a more comprehensive comparison.\n",
    "4. From the product of the comparison objects, we will be able to compare against hundreds of different documents.\n",
    "\n",
    "I'm going to make these classes local for now, but I may eventually package them. Just not right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0630e-0940-4bd2-9943-92cb4b6950c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages in full (for now, still building of course)\n",
    "\n",
    "import torch\n",
    "from sentence_transformer import SentenceTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "a4eeb6b7-f805-4612-888c-1866e508fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speech():\n",
    "\n",
    "    model = SentenceTransformer(\"thenlper/gte-small\")\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.metadata = data[['ID', 'Title']]\n",
    "        self.document_body = data['Document Body'].split('.')\n",
    "        self.document_body = [x for x in self.document_body if len(x) > 30]\n",
    "        self.embeddings = model.encode(self.document_body)\n",
    "\n",
    "class Comparison():\n",
    "\n",
    "    model = SentenceTransformer(\"thenlper/gte-small\")\n",
    "    \n",
    "    def __init__(self, speech1, speech2):\n",
    "        self.speech1 = speech1\n",
    "        self.speech2 = speech2\n",
    "        self.similarities = model.similarity(speech1.embeddings, speech2.embeddings)\n",
    "\n",
    "    def find_similar_phrases(self, lower_bound = 0.000, upper_bound = 1.001):\n",
    "        # the idea here is that one can enter a similarity threshold in float format and this will return a dataframe of all similar sentences\n",
    "        # within that threshold, along with threshold scores\n",
    "        # this can be called public facing but is also used in the later functions.\n",
    "\n",
    "        # FLAGGING - THERE IS A BUG SOMEWHERE IN THIS METHOD\n",
    "        \n",
    "        indices = torch.nonzero((self.similarities >= lower_bound) & (self.similarities < upper_bound))\n",
    "        indices = pd.DataFrame(indices)\n",
    "        indices.rename(columns={0: 'Index_1', 1: 'Index_2'}, inplace=True)\n",
    "        scores = []\n",
    "        for index, row in indices.iterrows():\n",
    "            first = row['Index_1']\n",
    "            second = row['Index_2']\n",
    "            scores.append(round(float(self.similarities[first][second]),3))\n",
    "        indices['Speech_1'] = indices['Index_1'].map(lambda x: self.speech1.document_body[x])\n",
    "        indices['Speech_2'] = indices['Index_2'].map(lambda x: self.speech2.document_body[x])\n",
    "        indices['Similarity_score'] = scores\n",
    "        return indices\n",
    "\n",
    "    def similarity_stats(self):\n",
    "        # here I want to find the average semantic similarity across two texts\n",
    "        # this is not going to be a true average: rather, it will bin sentences by semantic similarity\n",
    "        # I am thinking of implementing some sort of hash table to prevent a sentence from being compared to too many other sentences\n",
    "        # I want to store these attributes to be used in show_comparison()\n",
    "\n",
    "        # For now, let's just have two bins: above 0.95 and between 0.90-0.95\n",
    "        near_identical = self.find_similar_phrases(lower_bound = 0.95)\n",
    "        paraphrase = self.find_similar_phrases(lower_bound = 0.90, upper_bound = 0.95)\n",
    "\n",
    "        # now I want to take near_identical as a percentage of each speech\n",
    "        copy_rate_1 = round(len(near_identical) / len(self.speech1.document_body),3)\n",
    "        copy_rate_2 = round(len(near_identical) / len(self.speech2.document_body),3)\n",
    "        paraphrase_rate_1 = round(len(paraphrase) / len(self.speech1.document_body),3)\n",
    "        paraphrase_rate_2 = round(len(paraphrase) / len(self.speech2.document_body),3)\n",
    "        values = {'Near Match': len(near_identical), 'Paraphrase': len(paraphrase), 'NM - % of Speech 1': copy_rate_1,\n",
    "                 'NM - % of Speech 2': copy_rate_2, 'P - % of Speech 1': paraphrase_rate_1, 'P - % of Speech 2': paraphrase_rate_2}\n",
    "        return values\n",
    "        \n",
    "\n",
    "    def show_comparison(self):\n",
    "        # here I want to create an array/list-like object to return from the comparison so we can compare across comparisons.\n",
    "        # Eventually, this will contain more of the metdata, but for now it is limited.\n",
    "        values = self.similarity_stats\n",
    "\n",
    "        # I may not work on this today, but it is important that we label each comparison array/list/whatever\n",
    "        # with at a minimum the document IDs being compared\n",
    "        # at a maximum I want IDs, titles, versions, dates\n",
    "        pass\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "387def65-4ccc-4e3d-b32d-829735fd02c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "32041.0\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print((len(documents)*0.5)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a7f40-fe6d-45b1-a696-4c55a0082213",
   "metadata": {},
   "source": [
    "There are 358 documents. Comparing each of them to every other possible document gives us a time complexity of $O(\\frac{1}{2}n^2)$, which we can see already means a total of over 30k comparisons just on this dataset. I think this would not be too onerous given the small size, but if we are analyzing the entire corpus of Bond's work it might be quite large. So filtering will be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "44d5f97f-c935-47de-9efe-5281665160d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speeches making observations about the recent election and its effects upon black people, 1972 November (Doc 3 of 3)\n",
      "\n",
      "(117, 384)\n",
      "\n",
      "   Index_1  Index_2                                           Speech_1  \\\n",
      "0        0        0  Now that the nation's voters — at least, 54% o...   \n",
      "1        1        1  \\nThe choice, simply put, was between the past...   \n",
      "2        2        2  \\nThose who believed Gallup and Harris knew th...   \n",
      "3        3        3   We learned that Jews, worried about quotas an...   \n",
      "4        5        4  ] - ---- -- --- -\\nIf the election on November...   \n",
      "\n",
      "                                            Speech_2  Similarity_score  \n",
      "0  Now that the nation's voters — at least, 54% o...             1.000  \n",
      "1   \\nThe choice, simply put, was between the pas...             1.000  \n",
      "2  \\nThose who believed Gallup and Harris knew th...             1.000  \n",
      "3   We learned that Jews, worried about quotas an...             0.992  \n",
      "4  \\nIf the election on November 7th illuminated ...             0.994  \n",
      "\n",
      "{'Near Match': 111, 'Paraphrase': 11, 'NM - % of Speech 1': 0.597, 'NM - % of Speech 2': 0.949, 'P - % of Speech 1': 0.059, 'P - % of Speech 2': 0.094}\n"
     ]
    }
   ],
   "source": [
    "# testing cell\n",
    "\n",
    "speech_1 = Speech(documents_test.loc[0])\n",
    "print(speech_1.metadata['Title'])\n",
    "# I want a regular expression to pull out as much date information as I can to make this a useful tool I think, but that's late stage.\n",
    "print()\n",
    "speech_2 = Speech(documents_test.loc[1])\n",
    "print(speech_2.embeddings.shape)\n",
    "print()\n",
    "speeches_comparison = Comparison(speech_1, speech_2)\n",
    "print((speeches_comparison.find_similar_phrases(lower_bound = 0.90).head()))\n",
    "print()\n",
    "print(speeches_comparison.similarity_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0997cac-a136-4d26-922a-f1dc9fd6260d",
   "metadata": {},
   "source": [
    "### Thoughts at this point\n",
    "\n",
    "This is kind of a fun concept! Worth noting that more than 100% of Speech 2 is marked in some way - Speech 3 clearly takes Speech 2 and adds onto it, probably splitting certain sentences into two or reiterating a point of some sort. Let's quickly look at two documents that aren't the same version, but are close chronologically. We're also going to test creating a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "0495f96b-bd31-481b-9dd3-9ef8622e81a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Box</th>\n",
       "      <th>Document Length</th>\n",
       "      <th>Workflow Stage</th>\n",
       "      <th>Image Filename</th>\n",
       "      <th>Image Identifier</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Document Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>665</td>\n",
       "      <td>Speeches making observations about the recent ...</td>\n",
       "      <td>Box 3 Folder 31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Early Access</td>\n",
       "      <td>PJB665_mss13347-b3-f31_0001.tif\\n, PJB665_mss1...</td>\n",
       "      <td>3186999, 3187000, 3187001, 3187002, 3187003, 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\nNow that the nations voters — at least, 54%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>663</td>\n",
       "      <td>Speech about the upcoming presidential electio...</td>\n",
       "      <td>Box 3 Folder 30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Early Access</td>\n",
       "      <td>PJB663_mss13347-b3-f30_0036.tif\\n, PJB663_mss1...</td>\n",
       "      <td>3187085, 3187086, 3187087, 3187088, 3187089, 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The election approaching on November seventh i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   ID                                              Title  \\\n",
       "0      7  665  Speeches making observations about the recent ...   \n",
       "1      8  663  Speech about the upcoming presidential electio...   \n",
       "\n",
       "               Box  Document Length Workflow Stage  \\\n",
       "0  Box 3 Folder 31             24.0   Early Access   \n",
       "1  Box 3 Folder 30             19.0   Early Access   \n",
       "\n",
       "                                      Image Filename  \\\n",
       "0  PJB665_mss13347-b3-f31_0001.tif\\n, PJB665_mss1...   \n",
       "1  PJB663_mss13347-b3-f30_0036.tif\\n, PJB663_mss1...   \n",
       "\n",
       "                                    Image Identifier Image URL  \\\n",
       "0  3186999, 3187000, 3187001, 3187002, 3187003, 3...       NaN   \n",
       "1  3187085, 3187086, 3187087, 3187088, 3187089, 3...       NaN   \n",
       "\n",
       "                                       Document Body  \n",
       "0  1\\nNow that the nations voters — at least, 54%...  \n",
       "1  The election approaching on November seventh i...  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_test_2 = documents.iloc[3:5].reset_index()\n",
    "documents_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "c67d0c0c-8585-406b-b7ed-8e67d7b33fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Speech at 0x29aafd484a0>, <__main__.Speech at 0x29aa2cc5df0>]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches = []\n",
    "for index, row in documents_test_2.iterrows():\n",
    "    new_speech = Speech(row)\n",
    "    speeches.append(new_speech)\n",
    "\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52572be-312b-4a9c-b322-54b1369f6535",
   "metadata": {},
   "source": [
    "Excellent! The objects are being stored correctly in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "ab0a27cc-b983-4ab2-96e8-4a510b1dc2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index_1  Index_2                                           Speech_1  \\\n",
      "0         8        9   It meant re-installing in power those who bel...   \n",
      "1        21       11   It, additionally, means an end for the moment...   \n",
      "2        23       14  \"\\n\"Our ideal is a country where every America...   \n",
      "3        25       15      \" ] 5\\nOur reality needs no full recital here   \n",
      "4        28       17   In sum, we know that our society is not funct...   \n",
      "5        30       18  \" the Coalition said, \"our paralysis of spirit...   \n",
      "6        31       19   Indeed, we must marshal our good sense and ou...   \n",
      "7        32       20                   There is no sensible alternative   \n",
      "8        33       21  \"\\nIn the Coalition view \"America must pursue ...   \n",
      "9        34       22  \" It must try to:\\nAchieve full employment wit...   \n",
      "10       35       23  \\n\"Provide all citizens with an equal opportun...   \n",
      "11       36       24  \\nGuarantee that no American will go without t...   \n",
      "12       38       25         We can move a long way toward them by 1976   \n",
      "13       42       28  \\nEveryone knows, or ought to know, that there...   \n",
      "14       43       29   It is race that elected our present President...   \n",
      "15       44       30  \\nFor the past several years, abundant solutio...   \n",
      "16       45       31  \\nThere are several solutions that, if impleme...   \n",
      "17       46       32  \\nThe nation could adopt, and strive for, a po...   \n",
      "18       47       33  \\nEqual opportunity, both racially and sexuall...   \n",
      "19       50       35  \\nThe institution of a national health insuran...   \n",
      "20       54       37  \\nThis is a drive that must spring from a care...   \n",
      "21       56       38  ] Since Richard Nixon took office in 1968, we ...   \n",
      "22       57       39    \\nWe will select a new Congress in 1972 as well   \n",
      "23       58       40   These for the most part must be new men and w...   \n",
      "24       59       41   It should be a Congress that would reject Nix...   \n",
      "25       60       42            \\nSuch a transformation can be achieved   \n",
      "26       61       43  \\nTo do so, you must be prepared to confront s...   \n",
      "27       89      101   In both cases, a President made a cynical dea...   \n",
      "28       90      102  \\nThe promises made then that Black people wou...   \n",
      "29       91      103   Instead of fulfilling the dream, then as now:...   \n",
      "30       92      103  ] socia\\n18\\nsocial justice could be achieved ...   \n",
      "31       94      104  ]\\nWe are now through with the two major natio...   \n",
      "32       95      105  \\nIn a few weeks we will, hopefully, all go to...   \n",
      "33      119       47   That's quite fine in infantile campus revolut...   \n",
      "\n",
      "                                             Speech_2  Similarity_score  \n",
      "0    It means re-installing in power those who bel...             0.966  \n",
      "1    It, additionally, means an end for the moment...             1.000  \n",
      "2   \"\\n\"Our ideal is country where every American ...             0.990  \n",
      "3          \"\\n\"Our reality needs no full recital here             0.981  \n",
      "4    In sum, we know that our society is not funct...             1.000  \n",
      "5   \"\\n\"But if we solve the greatest of our ills,\"...             0.972  \n",
      "6    Indeed, we must marshal our good sense and ou...             1.000  \n",
      "7                    There is no sensible alternative             1.000  \n",
      "8   \"\\nIn the Coalition view \"America must pursue ...             1.000  \n",
      "9   \" It must try to:\\n\"Achieve full employment wi...             0.990  \n",
      "10  \\n\"Provide all citizens with an equal opportun...             0.986  \n",
      "11  \\n\"Guarantee that no American will go without ...             0.996  \n",
      "12         We can move a long way toward them by 1976             1.000  \n",
      "13  \\nEveryone knows, or ought to know, that there...             0.989  \n",
      "14   It is race that elected our present President...             1.000  \n",
      "15  \\nFor the past several years, abundant solutio...             1.000  \n",
      "16  \\nThere are several solutions that, if impleme...             1.000  \n",
      "17  \\nThe nation could adopt, and strive for, a po...             1.000  \n",
      "18  \\nEqual opporuntiy, both racially and sexually...             0.972  \n",
      "19  \\nThe institution of a national health insuran...             1.000  \n",
      "20  \\nThis is a drive that must spring from a care...             1.000  \n",
      "21  \\nSince Richard Nixon took office in 1968, we ...             0.995  \n",
      "22    \\nWe will select a new Congress in 1972 as well             1.000  \n",
      "23   These for the most part must be new men and w...             0.997  \n",
      "24   It should be a Congress that would reject Nix...             1.000  \n",
      "25            \\nSuch a transformation can be achieved             1.000  \n",
      "26  \\nTo do so, you must be prepared to confront s...             1.000  \n",
      "27   In both cases, a President made a deal, not j...             0.985  \n",
      "28  \\nThe promises made then that Black people wou...             1.000  \n",
      "29   Instead of fulfilling the dream, then as now:...             0.958  \n",
      "30   Instead of fulfilling the dream, then as now:...             0.960  \n",
      "31  2\\nWe are through with the two major national ...             0.992  \n",
      "32  \\nIn a few weeks we will, hopefully, all go to...             1.000  \n",
      "33  \"\\nThat's fine in infantile campus revolutiona...             0.967  \n"
     ]
    }
   ],
   "source": [
    "new_comparison = Comparison(speeches[0], speeches[1])\n",
    "\n",
    "print((new_comparison.find_similar_phrases(lower_bound = 0.95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "04f67f80-073e-42df-a186-02eef1cdd9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index_1  Index_2                                           Speech_1  \\\n",
      "0         7        8  \"\\n2\\nFor Black people in America, the electio...   \n",
      "1         9       10   It meant giving a four year free hand to the ...   \n",
      "2        10        2   Nixon now has four more years to put his men ...   \n",
      "3        11        3  \\nHe will continue to set the budget and name ...   \n",
      "4        12        5   ] 4\\nHe will continue to decide whether our w...   \n",
      "5        17       37   ] 9\\nFor too many young Americans, the exch p...   \n",
      "6        20       10  ]\\nfundamental constitutionally guaranteed per...   \n",
      "7        22       12  \\nA short while ago, the National Urban Coalit...   \n",
      "8        26       16                 We know that cities are in trouble   \n",
      "9        27       16   That poverty continues in the midst of wealth...   \n",
      "10       34       32  \" It must try to:\\nAchieve full employment wit...   \n",
      "11       39       54  \"1\\n[Handwritten line with arrow pointing to p...   \n",
      "12       39       64  \"1\\n[Handwritten line with arrow pointing to p...   \n",
      "13       40       26  ]\\nBut in addition to the Coalition's major go...   \n",
      "14       41       27     , and the goal its containment and eradication   \n",
      "15       46       22  \\nThe nation could adopt, and strive for, a po...   \n",
      "16       48       34  \\nThrough public service employment, increased...   \n",
      "17       49       34  ] social insurance by radically altering publi...   \n",
      "18       51       54  \\n[Handwritten line with arrow pointing to par...   \n",
      "19       51       62  \\n[Handwritten line with arrow pointing to par...   \n",
      "20       51       64  \\n[Handwritten line with arrow pointing to par...   \n",
      "21       52       36  ]\\nNone of these things will be done, however,...   \n",
      "22       87      100  ]\\nThe question remains for the future — will ...   \n",
      "23       88      100                  ]\\nthe years after Reconstruction   \n",
      "24       93       54  2\\n[A handwritten line is drawn between these ...   \n",
      "25       93       62  2\\n[A handwritten line is drawn between these ...   \n",
      "26       93       64  2\\n[A handwritten line is drawn between these ...   \n",
      "27      102       91  \\nPolitics, as it has existed for us, is changing   \n",
      "\n",
      "                                             Speech_2  Similarity_score  \n",
      "0   \\nFor Black Americans, an electoral victory in...             0.912  \n",
      "1    It means giving a four-year free hand to men ...             0.946  \n",
      "2    He\\nHe will place his men on the Supreme Cour...             0.913  \n",
      "3   \\nHe will name the directors and set the budge...             0.950  \n",
      "4   \\nHe will decide whether stocks go up or down;...             0.929  \n",
      "5   \\nThis is a drive that must spring from a care...             0.902  \n",
      "6    It means giving a four-year free hand to men ...             0.902  \n",
      "7   \\nA short while ago, the National Urban Coalit...             0.947  \n",
      "8    We know that cities are in trouble, that pove...             0.936  \n",
      "9    We know that cities are in trouble, that pove...             0.945  \n",
      "10  \\nThe nation could adopt, and strive for, a po...             0.920  \n",
      "11  \\n[Several lines of penciled-in shorthand appe...             0.901  \n",
      "12   [Pencil lines appear at the end of this parag...             0.906  \n",
      "13  \"1\\nBut in addition to the Coaliton's major go...             0.945  \n",
      "14   That ill is racism and the goal its containme...             0.923  \n",
      "15  \" It must try to:\\n\"Achieve full employment wi...             0.920  \n",
      "16  \\nThrough public service employment, increased...             0.923  \n",
      "17  \\nThrough public service employment, increased...             0.945  \n",
      "18  \\n[Several lines of penciled-in shorthand appe...             0.913  \n",
      "19  ]\\n[Shorthand in pencil appears around the nex...             0.903  \n",
      "20   [Pencil lines appear at the end of this parag...             0.911  \n",
      "21  \\nNone of these things will be done, however, ...             0.944  \n",
      "22  \\nWhat is happening now happened once before i...             0.905  \n",
      "23  \\nWhat is happening now happened once before i...             0.908  \n",
      "24  \\n[Several lines of penciled-in shorthand appe...             0.911  \n",
      "25  ]\\n[Shorthand in pencil appears around the nex...             0.907  \n",
      "26   [Pencil lines appear at the end of this parag...             0.902  \n",
      "27  \\nWe are now politically where we were twelve ...             0.910  \n"
     ]
    }
   ],
   "source": [
    "print((new_comparison.find_similar_phrases(lower_bound = 0.90, upper_bound = 0.95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e66dc0b3-6570-498f-abea-7e87f952528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Near Match': 34, 'Paraphrase': 28, 'NM - % of Speech 1': 0.264, 'NM - % of Speech 2': 0.315, 'P - % of Speech 1': 0.217, 'P - % of Speech 2': 0.259}\n"
     ]
    }
   ],
   "source": [
    "print(new_comparison.similarity_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc1904-4ace-4ee8-a05c-bb9e349cc84c",
   "metadata": {},
   "source": [
    "Isn't that cool! It admittedly picks up some weird stuff, like editorial language, and I need to do a better job of cleaning the data (I'm sure I'm missing out on lots of stuff due to various reasons). But it shows how Bond reuses certain phrases across time. And we can plot this on a much larger scale, which I want to do next.\n",
    "\n",
    "This is where I think the FAISS clustering step will come in handy - it will make it easier to make connections across the entire corpus. But we can already begin to see how this can create a history of Bond's speechwriting, and identify things that relate to Bond's core tenets. This is a decent stopping point for now, though."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
