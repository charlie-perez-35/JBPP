## Semantic Similarity Search Project

### Feb-?, 2025

I wanted to make a bit of a map for this project. The other projects are much more straightforward data pipelining,
but this is my attempt at a bit of high-level analysis using modern tools like LLM embeddings and NLTK sentence tokenization.


Some acknowledgements: the embedding model I am using is [GTE-small](https://huggingface.co/thenlper/gte-small) which was developed by the
Alibaba DAMO Academy. I am loosely following a framework created by Lucian Li, University of Illinois Urbana-Champaign,
as discussed in [Tracing the Genealogies of Ideas](https://arxiv.org/pdf/2402.01661v1). I should also thank Dr.
Rafael Alvarado, University of Virginia School of Data Science, whose class on exploratory text analytics has aided me
immensely in structuring this project. And of course, thanks to the Julian Bond Papers Project, which has allowed me to
spend their resources on my little pet project here in the vague hope that something useful comes out of it.

*Should have a better citation setup here*

The earliest attempts can be found in the `Outdated` folder. My better efforts are currently in two Jupyter Notebooks:

> embeddings_better_schema.ipynb: sets up a kind of vaguely relational system for organizing the data, including the tokenization, embedding, and similarity calculation processes.


> embeddings_visualizations.ipynb: begins the analysis process

This is of course a work in progress and will be updated in the near future.
